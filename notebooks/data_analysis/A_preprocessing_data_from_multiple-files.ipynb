{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ac01bc",
   "metadata": {},
   "source": [
    "# Video texture features and Motion tracking data Postprocessing \n",
    "Author(s): Miguel Xochicale @mxochicale    \n",
    "Contributor(s): Sujon Hekim\n",
    "\n",
    "## History\n",
    "* 17th May 2023: Add prototype\n",
    "* 10th Aug 2023: Adds saving dataframes in cvs files\n",
    "* 26th Sep 2023: Reads data from Thu-24-Aug-2023\n",
    "* 3rd Oct 2023: Adds time to check execution time of cells\n",
    "* 2-Apr-2024: adds light-demo-data\n",
    "\n",
    "## Summary\n",
    "\n",
    "\n",
    "### How to run the notebook\n",
    "1. Go to repository path: `$HOME/repositories/`\n",
    "Open repo in pycharm and in the terminal type:\n",
    "```\n",
    "git checkout main # or the branch\n",
    "git pull # to bring a local branch up-to-date with its remote version\n",
    "```\n",
    "\n",
    "2. Launch Notebook server. Go to you repository path: cd $HOME/repositories/ and type in the pycharm terminal:\n",
    "```\n",
    "conda activate *VE \n",
    "jupyter notebook --browser=firefox\n",
    "```\n",
    "which will open your web-browser.\n",
    "\n",
    "## References \n",
    "1. https://stackoverflow.com/questions/45704999/how-to-convert-vector-wrapped-as-string-to-numpy-array-in-pandas-dataframe\n",
    "2. https://github.com/YuxinZhaozyx/pytorch-VideoDataset/blob/master/datasets.py (Future work)\n",
    "3. https://stackoverflow.com/questions/65446464/how-to-convert-a-video-in-numpy-array\n",
    "4. https://matplotlib.org/stable/gallery/specialty_plots/mri_with_eeg.html#sphx-glr-gallery-specialty-plots-mri-with-eeg-py \n",
    "5. https://www.researchgate.net/publication/326881329_Medical_image_security_enhancement_using_two_dimensional_chaotic_mapping_optimized_by_self-adaptive_grey_wolf_algorithm \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf80206",
   "metadata": {},
   "source": [
    "## Setting imports and datasets paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7217b-05a2-464b-adbe-01ecd0c38ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentient.utils.utils import video_to_tensor, compute_texture_array_and_plot\n",
    "from sentient.utils.utils import data_frame_of_texture_analysis\n",
    "from sentient.utils.utils import get_and_plot_imu_data_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190058c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:41:47.145415Z",
     "start_time": "2023-06-24T22:41:47.136830Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from typing import Tuple, List\n",
    "\n",
    "HOME_PATH = os.path.expanduser(f'~')\n",
    "USERNAME = os.path.split(HOME_PATH)[1]\n",
    "REPOSITORY_PATH='repositories/sentient'\n",
    "\n",
    "##########################\n",
    "##SETTING DATA_PATHS\n",
    "#DATA_PATH='repositories/datasets/in2research2023/Thu-27-Jul-2023' \n",
    "DEMO_DATA_PATH='repositories/sentient/data/surgical-skill-assessment/demo-data-for-sentient/surgical-skill-assessment' \n",
    "\n",
    "# RAW_DATA_PATH='repositories/datasets/in2research2023/Thu-24-Aug-2023'\n",
    "# PREPROCESSED_DATA_PATH='repositories/datasets/in2research2023/Thu-24-Aug-2023-preprocessed'\n",
    "\n",
    "# FULL_REPO_DATA_PATH = HOME_PATH +'/' + RAW_DATA_PATH\n",
    "FULL_REPO_DATA_PATH = HOME_PATH +'/' + DEMO_DATA_PATH\n",
    "\n",
    "# FULL_REPO_PREPROCESSED_DATA_PATH = HOME_PATH +'/' + PREPROCESSED_DATA_PATH +'/'\n",
    "# os.makedirs(FULL_REPO_PREPROCESSED_DATA_PATH, exist_ok=True) \n",
    "\n",
    "# ## Printing Versions and paths\n",
    "# print(FULL_REPO_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc94bcd",
   "metadata": {},
   "source": [
    "# Reading video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f4372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:30.904233Z",
     "start_time": "2023-06-24T22:43:27.564573Z"
    }
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#### FOR TWO PARTICPATNS\n",
    "# PARTICIPANTNN = 'participant01'\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test01-rep01-1g-5mins' #51,328\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test01-rep02-1g-5mins' #51,178\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test02-rep01-1g-5mins' #49,183\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test02-rep02-1g-5mins' #47,577\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test03-rep01-1g-5mins' #48,688\n",
    "# PARTICIPANTNN_TESTNN = 'participant01-test03-rep02-1g-5mins'#48,789\n",
    "\n",
    "# PARTICIPANTNN = participant02\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test01-rep01-1g-5mins'#49,490\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test01-rep02-1g-5mins'#49,219\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test02-rep01-1g-5mins'#48,043\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test02-rep02-1g-5mins'#49,606\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test03-rep01-1g-5mins'#48,875\n",
    "# PARTICIPANTNN_TESTNN = 'participant02-test03-rep02-1g-5mins'#48,050\n",
    "\n",
    "# start_frame_number = 0\n",
    "# end_frame_number = 40000 #(resulted samples are end_frame_number-2)\n",
    "# display_factor_for_texture_analysis_array = 100000\n",
    "# # display_figures=False\n",
    "# display_figures=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f752a3-6c6d-4777-914c-9e4d916a467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "VIDEO_FILENAME=\"p01t01r01-60ss\" #total frames 7200\n",
    "# VIDEO_FILENAME=\"p01t02r01-60ss\" #total frames 7200\n",
    "# VIDEO_FILENAME=\"p01t03r01-60ss\" #total frames 7200\n",
    "\n",
    "start_frame_number = 0000\n",
    "end_frame_number = 7050 #(resulted samples are end_frame_number-2) \n",
    "display_factor_for_texture_analysis_array = 1000\n",
    "\n",
    "# display_figures=False\n",
    "display_figures=True\n",
    "\n",
    "CSV_FILENAME_FOR_TEXTURE_ANALYSIS=VIDEO_FILENAME+'_texture.csv'\n",
    "FULL_PATH_AND_AVI_FILE = os.path.join(FULL_REPO_DATA_PATH, VIDEO_FILENAME+'.mp4')\n",
    "FULL_PATH_AND_CSV_FILE = os.path.join(FULL_REPO_DATA_PATH, VIDEO_FILENAME+'.mp4.csv')\n",
    "\n",
    "#ORIGINAL\n",
    "# CSV_FILENAME_FOR_TEXTURE_ANALYSIS=PARTICIPANTNN_TESTNN+'.csv'\n",
    "# FULL_PATH_AND_AVI_FILE = os.path.join(FULL_REPO_DATA_PATH, PARTICIPANTNN, PARTICIPANTNN_TESTNN+'.avi')\n",
    "# FULL_PATH_AND_CSV_FILE = os.path.join(FULL_REPO_DATA_PATH, PARTICIPANTNN, PARTICIPANTNN_TESTNN+'.avi.csv')\n",
    "\n",
    "total_number_of_frames = end_frame_number - start_frame_number\n",
    "video, frames_timestam = video_to_tensor(FULL_PATH_AND_AVI_FILE, start_frame_number, end_frame_number)\n",
    "# num_frames, height, width = video.shape\n",
    "# print(f'num_frames: {num_frames}')\n",
    "# print(f'height: {height}')\n",
    "# print(f'width: {width}')\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aca3e3",
   "metadata": {},
   "source": [
    "# Generating texture_analysis_array and plotting frames and histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed983d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:46.518000Z",
     "start_time": "2023-06-24T22:43:40.615453Z"
    }
   },
   "outputs": [],
   "source": [
    "# This takes a while as it computes texture feature for each frame and save it in texture_analysis_array\n",
    "start_time = time.time()\n",
    "texture_analysis_array = compute_texture_array_and_plot(video, frames_timestam, display_figures, display_factor_for_texture_analysis_array)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56537774",
   "metadata": {},
   "source": [
    "# Plotting texture analysis of all frames in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d2e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:59.892073Z",
     "start_time": "2023-06-24T22:43:58.621981Z"
    }
   },
   "outputs": [],
   "source": [
    "df_texture_analysis = data_frame_of_texture_analysis(texture_analysis_array, start_frame_number, end_frame_number)\n",
    "# df_texture_analysis.to_csv(FULL_REPO_PREPROCESSED_DATA_PATH+PARTICIPANTNN_TESTNN+'_texture_analysis'+'.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fa4d8-bd9e-4092-958a-f66238726c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texture_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879bd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_texture_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0ca63-aa7b-4851-8c9c-b03578709dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_texture_analysis(dftrial01):\n",
    "    \"\"\"\n",
    "\n",
    "    TO ADD IN UTILS on 26Sep2023\n",
    "    TODO: https://seaborn.pydata.org/generated/seaborn.lineplot.html\n",
    "    \"\"\"\n",
    "        \n",
    "    fig, axs = plt.subplots(2,3, figsize=(12, 6))\n",
    "    ax = plt.gca()    \n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    \n",
    "    dftrial01.plot(x='frame_i', y='Contrast_normalised', ax=axs[0,0])\n",
    "    dftrial01.plot(x='frame_i', y='Correlation_normalised', ax=axs[0,1])\n",
    "    dftrial01.plot(x='frame_i', y='Dissimilarity_normalised', ax=axs[0,2])\n",
    "    dftrial01.plot(x='frame_i', y='Homogeneity_normalised', ax=axs[1,0])\n",
    "    dftrial01.plot(x='frame_i', y='Energy_normalised', ax=axs[1,1])\n",
    "    dftrial01.plot(x='frame_i', y='ASM_normalised', ax=axs[1,2])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_texture_analysis(df_texture_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e37dd6",
   "metadata": {},
   "source": [
    "## Reading and ploting csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:44:12.264545Z",
     "start_time": "2023-06-24T22:44:11.535541Z"
    }
   },
   "outputs": [],
   "source": [
    "df, ndf, nqdf = get_and_plot_imu_data_analysis(FULL_PATH_AND_CSV_FILE, start_frame_number, end_frame_number, display_figures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c831cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nqdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# To save full dataframe as cvs\n",
    "# df.to_csv(FULL_REPO_PREPROCESSED_DATA_PATH+PARTICIPANTNN_TESTNN+'_tracker_sensor'+'.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5f2e4-c386-44da-abce-897d0e2d255c",
   "metadata": {},
   "source": [
    "## Saving dataframes as cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d93491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a = df_texture_analysis[['frame_i', 'Contrast_normalised', 'Correlation_normalised', 'Dissimilarity_normalised', 'Energy_normalised', 'Homogeneity_normalised', 'ASM_normalised']]\n",
    "df_a = df_texture_analysis[['frame_i', 'Contrast_normalised', 'Correlation_normalised', 'Dissimilarity_normalised', 'Homogeneity_normalised']]\n",
    "\n",
    "df_b = df[['q0', 'q1', 'q2', 'q3']]\n",
    "dff = pd.concat([df_a, df_b], axis=1)\n",
    "print(dff)\n",
    "\n",
    "# dff.to_csv(FULL_REPO_PREPROCESSED_DATA_PATH+PARTICIPANTNN_TESTNN+'_normalised_quaternions'+'.csv', index=False) \n",
    "dff.to_csv(FULL_REPO_DATA_PATH+'/'+VIDEO_FILENAME+'_normalised_quaternions'+'.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474439c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0a184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
