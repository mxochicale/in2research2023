{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ac01bc",
   "metadata": {},
   "source": [
    "# Analysis of Video and Image Data for cropping and texture features\n",
    "Author(s): Miguel Xochicale @mxochicale    \n",
    "Contributor(s): \n",
    "\n",
    "## History\n",
    "* 17th May 2022: Add prototype\n",
    "\n",
    "## Summary\n",
    "\n",
    "\n",
    "### How to run the notebook\n",
    "1. Go to repository path: `$HOME/repositories/`\n",
    "Open repo in pycharm and in the terminal type:\n",
    "```\n",
    "git checkout main # or the branch\n",
    "git pull # to bring a local branch up-to-date with its remote version\n",
    "```\n",
    "\n",
    "2. Launch Notebook server. Go to you repository path: cd $HOME/repositories/ and type in the pycharm terminal:\n",
    "```\n",
    "mamba activate *VE \n",
    "jupyter notebook --browser=firefox\n",
    "```\n",
    "which will open your web-browser.\n",
    "\n",
    "## References \n",
    "1. https://stackoverflow.com/questions/45704999/how-to-convert-vector-wrapped-as-string-to-numpy-array-in-pandas-dataframe\n",
    "2. https://github.com/YuxinZhaozyx/pytorch-VideoDataset/blob/master/datasets.py (Future work)\n",
    "3. https://stackoverflow.com/questions/65446464/how-to-convert-a-video-in-numpy-array\n",
    "4. https://matplotlib.org/stable/gallery/specialty_plots/mri_with_eeg.html#sphx-glr-gallery-specialty-plots-mri-with-eeg-py \n",
    "5. https://www.researchgate.net/publication/326881329_Medical_image_security_enhancement_using_two_dimensional_chaotic_mapping_optimized_by_self-adaptive_grey_wolf_algorithm \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf80206",
   "metadata": {},
   "source": [
    "## Setting imports and datasets paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190058c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:41:47.145415Z",
     "start_time": "2023-06-24T22:41:47.136830Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from typing import Tuple, List\n",
    "\n",
    "HOME_PATH = os.path.expanduser(f'~')\n",
    "USERNAME = os.path.split(HOME_PATH)[1]\n",
    "REPOSITORY_PATH='repositories/in2research2023'\n",
    "\n",
    "\n",
    "###########################\n",
    "###SET DATA_PATH \n",
    "DATA_PATH='scripts/sensor-fusion'\n",
    "FULL_REPO_DATA_PATH = HOME_PATH +'/' + REPOSITORY_PATH +'/' + DATA_PATH\n",
    "\n",
    "\n",
    "###########################\n",
    "### experiments_13-Jul-2023\n",
    "AVI_FILE_01 = 'test01.avi'\n",
    "CSV_FILE_01 = 'test01.avi.csv'\n",
    "\n",
    "AVI_FILE_02 = 'test02.avi'\n",
    "CSV_FILE_02 = 'test02.avi.csv'\n",
    "\n",
    "\n",
    "FULL_PATH_AND_AVI_FILE_01 = os.path.join(FULL_REPO_DATA_PATH , AVI_FILE_01)\n",
    "FULL_PATH_AND_CSV_FILE_01 = os.path.join(FULL_REPO_DATA_PATH , CSV_FILE_01)\n",
    "\n",
    "FULL_PATH_AND_AVI_FILE_02 = os.path.join(FULL_REPO_DATA_PATH , AVI_FILE_02)\n",
    "FULL_PATH_AND_CSV_FILE_02 = os.path.join(FULL_REPO_DATA_PATH , CSV_FILE_02)\n",
    "\n",
    "\n",
    "## Printing Versions and paths\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "print(f'pandas Version: {pd.__version__}')\n",
    "print(f'seaborn Version: {sns.__version__}')\n",
    "print(f'numpy Version: {np.__version__}')\n",
    "print(f'cv2 Version: {cv2.__version__}')\n",
    "print(f'skimage Version: {skimage.__version__}')\n",
    "\n",
    "print(f'FULL_REPO_DATA_PATH: {FULL_REPO_DATA_PATH}')\n",
    "print(f'FULL_PATH_AND_CSV_FILE: {FULL_PATH_AND_CSV_FILE_01}')\n",
    "print(f'FULL_PATH_AND_AVI_FILE: {FULL_PATH_AND_AVI_FILE_01}')\n",
    "\n",
    "print(f'FULL_PATH_AND_CSV_FILE: {FULL_PATH_AND_CSV_FILE_02}')\n",
    "print(f'FULL_PATH_AND_AVI_FILE: {FULL_PATH_AND_AVI_FILE_02}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a662e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:41:54.608123Z",
     "start_time": "2023-06-24T22:41:54.584316Z"
    }
   },
   "outputs": [],
   "source": [
    "def msec_to_timestamp(current_timestamp: float) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Convert millisecond variable to a timestamp variable with the format minutes, seconds and milliseconds\n",
    "    \"\"\"\n",
    "    minutes = int(current_timestamp / 1000 / 60)\n",
    "    seconds = int(np.floor(current_timestamp / 1000) % 60)\n",
    "    ms = current_timestamp - np.floor(current_timestamp / 1000) * 1000\n",
    "\n",
    "    return minutes, seconds, '{:.3f}'.format(ms), '{:02d}:{:02d}:{:.3f}'.format(minutes, seconds, ms)\n",
    "\n",
    "    \n",
    "def masks_us_image(image_frame_array_1ch: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Hard mask pixels outside of scanning sector\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image_frame_array_1ch)\n",
    "\n",
    "    #                 top-left, \n",
    "    #                     top-right, \n",
    "    #                           bottom-right\n",
    "    #                                             arc \n",
    "    #                                                                         bottom-left\n",
    "    \n",
    "    #x_data = np.array([250, 380, 572,           454,321,165                   ,60])\n",
    "    #y_data = np.array([30, 30, 320,             389,421,382                   ,320 ])\n",
    "    \n",
    "    \n",
    "    x_data = np.array([250, 380, 572,           \n",
    "                       597,580,561,537,515,491,474,436,395,366,333,293,249,207,166,     97,77,61,42  #arc\n",
    "                       ,60])#bottom-left\n",
    "    y_data = np.array([30, 30, 320,             \n",
    "                       368,380,392,404,416,424,430,440,448,451,452,453,446,439,426,     398,388,380,366  #arc\n",
    "                       ,320 ]) #bottom-left\n",
    "    scan_arc_mask_v01 = np.vstack((x_data, y_data)).astype(np.int32).T\n",
    "\n",
    "\n",
    "    \n",
    "    #caliper_scale_mask = np.array([(1770, 120), (1810, 120), (1810, 930), (1770, 930)])\n",
    "    cv2.fillPoly(mask, [scan_arc_mask_v01],\n",
    "                (255, 255, 0))\n",
    "    maskedImage = cv2.bitwise_and(image_frame_array_1ch, image_frame_array_1ch, mask=mask)\n",
    "\n",
    "    return maskedImage\n",
    "\n",
    "\n",
    "\n",
    "def GLCMs(img):\n",
    "    \"\"\"\n",
    "    Calculating gray level co-occurrence matrices (GLCMs)\n",
    "    https://scikit-image.org/docs/dev/auto_examples/features_detection/\n",
    "           plot_glcm.html#sphx-glr-auto-examples-features-detection-plot-glcm-py\n",
    "\n",
    "    Haralick, RM.; Shanmugam, K., “Textural features for image classification” \n",
    "        IEEE Transactions on systems, man, and cybernetics 6 (1973): 610-621. \n",
    "        [DOI:10.1109/TSMC.1973.4309314](https://doi.org/10.1109/TSMC.1973.4309314)\n",
    "    PDF: http://haralick-org.torahcode.us/journals/TexturalFeaturesHaralickShanmugamDinstein.pdf\n",
    "    google-citations: https://scholar.google.com/scholar?cites=\n",
    "                        13863271628667072083&as_sdt=2005&sciodt=0,5&hl=en\n",
    "   \n",
    "    \"\"\"\n",
    "    return graycomatrix(img,[1],[0],levels=256)\n",
    "\n",
    "def Contrast(R):\n",
    "    ct = graycoprops(R,prop='contrast')\n",
    "    return ct\n",
    "\n",
    "def Correlation(R):\n",
    "    cn = graycoprops(R,prop='correlation')\n",
    "    return cn\n",
    "\n",
    "def Dissimilarity(R):\n",
    "    d = graycoprops(R,prop='dissimilarity')\n",
    "    return d\n",
    "\n",
    "def Energy(R):\n",
    "    e = graycoprops(R,prop='energy')\n",
    "    return e\n",
    "\n",
    "def Homogeneity(R):\n",
    "    h = graycoprops(R,prop='homogeneity')\n",
    "    return h\n",
    "\n",
    "def ASM(R):\n",
    "    a = graycoprops(R,prop='ASM')\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "def video_to_tensor(FULL_PATH_AND_AVI_FILE, start_frame_number, end_frame_number):\n",
    "    cap = cv2.VideoCapture(FULL_PATH_AND_AVI_FILE)\n",
    "    if cap.isOpened() == False:\n",
    "        print('[ERROR] [ViewVideoDataset.__getitem__()] Unable to open video ' + FULL_PATH_AND_AVI_FILE)\n",
    "        exit(-1)\n",
    "\n",
    "    # Get parameters of input video\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(np.ceil(cap.get(cv2.CAP_PROP_FPS)))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Print video features\n",
    "    print(f'  ')\n",
    "    print(f'  ')\n",
    "    print(f'  VIDEO_FEATURES')\n",
    "    print(f'    video_name={FULL_PATH_AND_AVI_FILE}')\n",
    "    print(f'    Frame_height={frame_height}, frame_width={frame_width} fps={fps} nframes={frame_count} ')\n",
    "    print(f'  ')\n",
    "    print(f'  ')\n",
    "    # # #         if start_frame_number >= end_frame_number:\n",
    "    # # #             raise Exception(\"start frame number must be less than end frame number\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_number)\n",
    "    frames_numpy_ndarray=[]\n",
    "    frames_torch = []\n",
    "    frames_timestamp = []\n",
    "\n",
    "    # pbar = tqdm(total=total_number_of_frames - 1)\n",
    "    while cap.isOpened():\n",
    "        success, image_frame_3ch_i = cap.read()\n",
    "\n",
    "        if not success and len(frames_torch) < 1:\n",
    "            print(f'[ERROR] {FULL_PATH_AND_AVI_FILE}')\n",
    "            exit(-1)\n",
    "            break\n",
    "\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) >= end_frame_number:\n",
    "            break\n",
    "\n",
    "        frame_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        current_frame_timestamp = msec_to_timestamp(frame_msec)\n",
    "        #print(current_frame_timestamp)#(0, 33, '333.333', '00:33:333.333')\n",
    "        #print(current_frame_timestamp[2])#'00:33:333.333'\n",
    "        #print(current_frame_timestamp[3])#00:33:333.333\n",
    "\n",
    "\n",
    "        #(H x W x C) to (C x H x W)\n",
    "        #print(type(image_frame_3ch_i))#    <class 'numpy.ndarray'>\n",
    "        #print(image_frame_3ch_i.shape)#(480, 640, 3)\n",
    "        image_frame_1ch_i = cv2.cvtColor(image_frame_3ch_i, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        frames_numpy_ndarray.append(image_frame_1ch_i)\n",
    "        #frames_numpy_ndarray.append(masks_us_image(image_frame_1ch_i))\n",
    "\n",
    "        frames_timestamp.append(current_frame_timestamp[3])\n",
    "\n",
    "    #     frame_torch = torch.from_numpy(image_frame_3ch_i).float()\n",
    "    #     frame_torch = frame_torch.squeeze()  # Fake batch dimension to be \"H,W,C\"\n",
    "    #     print(type(frame_torch))#<class 'torch.Tensor'>\n",
    "    #     print(frame_torch.shape)#torch.Size([480, 640, 3])\n",
    "\n",
    "    # # #             cropped_image_frame_ = cropped_frame(masked_frame, self.crop_bounds)\n",
    "    # # #             frame_torch = ToImageTensor(cropped_image_frame_)\n",
    "\n",
    "    video = np.stack(frames_numpy_ndarray, axis=0) # dimensions (Fi, H, W, C)\n",
    "    cap.release()\n",
    "\n",
    "    return video, frames_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc94bcd",
   "metadata": {},
   "source": [
    "# Reading video and plotting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f4372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:30.904233Z",
     "start_time": "2023-06-24T22:43:27.564573Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "start_frame_number = 000\n",
    "end_frame_number = 500\n",
    "total_number_of_frames = end_frame_number - start_frame_number\n",
    "\n",
    "video_01, frames_timestam_01 = video_to_tensor(FULL_PATH_AND_AVI_FILE_01, start_frame_number, end_frame_number)\n",
    "print(video_01.shape) \n",
    "\n",
    "video_02, frames_timestam_02 = video_to_tensor(FULL_PATH_AND_AVI_FILE_02, start_frame_number, end_frame_number)\n",
    "print(video_02.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aca3e3",
   "metadata": {},
   "source": [
    "# Plotting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed983d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:46.518000Z",
     "start_time": "2023-06-24T22:43:40.615453Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_us_hist(im):\n",
    "    im=video[frame_i]\n",
    "    fig = plt.figure(dpi=50, figsize=(15, 5))\n",
    "\n",
    "    \n",
    "    ax0 = fig.add_subplot(1, 2, 1)\n",
    "    ax0.imshow(im, cmap='gray')\n",
    "\n",
    "    \n",
    "    ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    #im = np.ravel(im)\n",
    "    #im = im[np.nonzero(im)]  # Ignore the background\n",
    "    #im = im / (2**16 - 1)  # Normalize\n",
    "    #ax1.hist(im, bins=10)\n",
    "    #https://matplotlib.org/stable/gallery/specialty_plots/\n",
    "           #mri_with_eeg.html#sphx-glr-gallery-specialty-plots-mri-with-eeg-py\n",
    "    \n",
    "    im = np.ravel(im)/256 # Normalize\n",
    "    im = im[np.nonzero(im)]  # Ignore the background\n",
    "    ax1.hist(im, bins=256, range=(0.0, 1.0))\n",
    "    #https://matplotlib.org/stable/tutorials/introductory/images.html#sphx-glr-tutorials-introductory-images-py\n",
    "    \n",
    "    ax1.minorticks_on()\n",
    "    ax1.set_xlabel('Normalised Intensity Values')\n",
    "    ax1.set_ylabel('Normalised Density')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "texture_analysis_array_01 = []    \n",
    "for frame_i in range(len(video_01)):\n",
    "    \n",
    "    # Compute Grey-Level-Co-occurrence Matrix    \n",
    "    R=GLCMs(video_01[frame_i])\n",
    "\n",
    "    # Calculating texture property Contrast\n",
    "    con = Contrast(R)\n",
    "\n",
    "    # Calculating texture property Correlation\n",
    "    cor = Correlation(R)\n",
    "\n",
    "    # Calculating texture property Dissimilarity\n",
    "    dis = Dissimilarity(R)\n",
    "\n",
    "    # Calculating texture property Energy\n",
    "    en = Energy(R)\n",
    "\n",
    "    # Calculating texture property Homogeneity\n",
    "    homo = Homogeneity(R)\n",
    "    \n",
    "    # Calculating texture property ASM\n",
    "    asm = ASM(R)\n",
    "    \n",
    "    texture_analysis_array_01.append([con,cor,dis,en,homo,asm])\n",
    "    #print(con,cor,dis,en,homo, asm) \n",
    "    \n",
    "    if frame_i % 250 == 0:\n",
    "        print(f'frame_i: {frame_i}, timestamp {frames_timestam_01[frame_i]}')\n",
    "        display_us_hist(frame_i)\n",
    "\n",
    "    \n",
    "    #plt.savefig('filename'+str(frame_i)+'.png', dpi=300)\n",
    "\n",
    "# print(texture_analysis_array)  \n",
    "\n",
    "\n",
    "\n",
    "texture_analysis_array_02 = []    \n",
    "for frame_i in range(len(video_02)):\n",
    "    \n",
    "    # Compute Grey-Level-Co-occurrence Matrix    \n",
    "    R=GLCMs(video_02[frame_i])\n",
    "\n",
    "    # Calculating texture property Contrast\n",
    "    con = Contrast(R)\n",
    "\n",
    "    # Calculating texture property Correlation\n",
    "    cor = Correlation(R)\n",
    "\n",
    "    # Calculating texture property Dissimilarity\n",
    "    dis = Dissimilarity(R)\n",
    "\n",
    "    # Calculating texture property Energy\n",
    "    en = Energy(R)\n",
    "\n",
    "    # Calculating texture property Homogeneity\n",
    "    homo = Homogeneity(R)\n",
    "    \n",
    "    # Calculating texture property ASM\n",
    "    asm = ASM(R)\n",
    "    \n",
    "    texture_analysis_array_02.append([con,cor,dis,en,homo,asm])\n",
    "    #print(con,cor,dis,en,homo, asm) \n",
    "    \n",
    "    if frame_i % 250 == 0:\n",
    "        print(f'frame_i: {frame_i}, timestamp {frames_timestam_02[frame_i]}')\n",
    "        display_us_hist(frame_i)\n",
    "\n",
    "    \n",
    "    #plt.savefig('filename'+str(frame_i)+'.png', dpi=300)\n",
    "\n",
    "# print(texture_analysis_array)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56537774",
   "metadata": {},
   "source": [
    "# Plotting texture analysis of all frames in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d2e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:59.892073Z",
     "start_time": "2023-06-24T22:43:58.621981Z"
    }
   },
   "outputs": [],
   "source": [
    "### Video01    \n",
    "texture_analysis_np_array_01 = np.stack(texture_analysis_array_01, axis=0) \n",
    "texture_analysis_np_array_01 = texture_analysis_np_array_01.transpose()\n",
    "texture_analysis_np_array_01 = texture_analysis_np_array_01.squeeze()\n",
    "# print(texture_analysis_np_array)\n",
    "# print(texture_analysis_np_array[0])\n",
    "\n",
    "df_texture_analysis_01 = pd.DataFrame( \n",
    "    {\n",
    "        'frame_i': np.arange(0, total_number_of_frames-1),\n",
    "        'Contrast': texture_analysis_np_array_01[0],\n",
    "        'Correlation': texture_analysis_np_array_01[1],\n",
    "        'Dissimilarity': texture_analysis_np_array_01[2],\n",
    "        'Energy': texture_analysis_np_array_01[3],\n",
    "        'Homogeneity': texture_analysis_np_array_01[4],\n",
    "        'ASM': texture_analysis_np_array_01[5]\n",
    "\n",
    "    }\n",
    "    )\n",
    "print(df_texture_analysis_01)\n",
    "\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ## Comment/uncomment any of the following lines to show however axis you would like to see in the plot\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Contrast', ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Correlation' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Dissimilarity' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Energy' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Homogeneity' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'ASM' , ax = ax )\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "## Comment/uncomment any of the following lines to show however axis you would like to see in the plot\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'Contrast', ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'Dissimilarity' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'Correlation' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'Energy' , ax = ax )\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'Homogeneity' , ax = ax )\n",
    "df_texture_analysis_01.plot( x = 'frame_i' , y = 'ASM' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #TODO: https://seaborn.pydata.org/generated/seaborn.lineplot.html    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0878e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:59.892073Z",
     "start_time": "2023-06-24T22:43:58.621981Z"
    }
   },
   "outputs": [],
   "source": [
    "### Video02    \n",
    "texture_analysis_np_array_02 = np.stack(texture_analysis_array_02, axis=0) \n",
    "texture_analysis_np_array_02 = texture_analysis_np_array_02.transpose()\n",
    "texture_analysis_np_array_02 = texture_analysis_np_array_02.squeeze()\n",
    "# print(texture_analysis_np_array)\n",
    "# print(texture_analysis_np_array[0])\n",
    "\n",
    "df_texture_analysis_02 = pd.DataFrame( \n",
    "    {\n",
    "        'frame_i': np.arange(0, total_number_of_frames-1),\n",
    "        'Contrast': texture_analysis_np_array_02[0],\n",
    "        'Correlation': texture_analysis_np_array_02[1],\n",
    "        'Dissimilarity': texture_analysis_np_array_02[2],\n",
    "        'Energy': texture_analysis_np_array_02[3],\n",
    "        'Homogeneity': texture_analysis_np_array_02[4],\n",
    "        'ASM': texture_analysis_np_array_02[5]\n",
    "\n",
    "    }\n",
    "    )\n",
    "print(df_texture_analysis_02)\n",
    "\n",
    "\n",
    "# ax = plt.gca()\n",
    "# ## Comment/uncomment any of the following lines to show however axis you would like to see in the plot\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Contrast', ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Correlation' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Dissimilarity' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Energy' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'Homogeneity' , ax = ax )\n",
    "# df_texture_analysis.plot( x = 'frame_i' , y = 'ASM' , ax = ax )\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "## Comment/uncomment any of the following lines to show however axis you would like to see in the plot\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'Contrast', ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'Dissimilarity' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'Correlation' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "ax = plt.gca()\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'Energy' , ax = ax )\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'Homogeneity' , ax = ax )\n",
    "df_texture_analysis_02.plot( x = 'frame_i' , y = 'ASM' , ax = ax )\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #TODO: https://seaborn.pydata.org/generated/seaborn.lineplot.html    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e37dd6",
   "metadata": {},
   "source": [
    "## Reading and ploting csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:44:12.264545Z",
     "start_time": "2023-06-24T22:44:11.535541Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(FULL_PATH_AND_CSV_FILE_01)\n",
    "# print(df)\n",
    "\n",
    "# # df = df.rename(columns={'Euler_computed [Roll, Pitch, Yaw]': 'Euler_computed'})\n",
    "df = df.rename(columns={'Sample number': 'Sample_number'})\n",
    "df = df.rename(columns={'Euler [Roll, Pitch, Yaw] LPMSB2': 'Euler_LPMSB2'})\n",
    "df = df.rename(columns={'Quaternions [q0, q1, q2, q3] LPMS-B2': 'Quaternions_LPMSB2'})\n",
    "\n",
    "df[['A','B','C']]=df.Euler_LPMSB2.str.split(',',expand=True)\n",
    "df['A']=df['A'].apply(   lambda x: x.replace('[','')   )\n",
    "df['C']=df['C'].apply(   lambda x:  x.replace(']','')   )\n",
    "df['A'] = pd.to_numeric(df['A'], errors='coerce')\n",
    "df['B'] = pd.to_numeric(df['B'], errors='coerce')\n",
    "df['C'] = pd.to_numeric(df['C'], errors='coerce')\n",
    "\n",
    "df[['q0','q1','q2', 'q3']]=df.Quaternions_LPMSB2.str.split(',',expand=True)\n",
    "df['q0']=df['q0'].apply(   lambda x: x.replace('[','')   )\n",
    "df['q3']=df['q3'].apply(   lambda x:  x.replace(']','')   )\n",
    "df['q0'] = pd.to_numeric(df['q0'], errors='coerce')\n",
    "df['q1'] = pd.to_numeric(df['q1'], errors='coerce')\n",
    "df['q2'] = pd.to_numeric(df['q2'], errors='coerce')\n",
    "df['q3'] = pd.to_numeric(df['q3'], errors='coerce')\n",
    "\n",
    "print(df.head())# #Print head of csv\n",
    "\n",
    "\n",
    "## EULER ANGLES\n",
    "ndf_a=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_a.insert(1, 'Euler_angle', str('alpha'), True)\n",
    "ndf_a.insert(2, 'Euler_val', df['A'], True)\n",
    "\n",
    "ndf_b=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_b.insert(1, 'Euler_angle', str('beta'), True)\n",
    "ndf_b.insert(2, 'Euler_val', df['B'], True)\n",
    "\n",
    "ndf_c=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_c.insert(1, 'Euler_angle', str('gamma'), True)\n",
    "ndf_c.insert(2, 'Euler_val', df['C'], True)\n",
    "\n",
    "ndf = pd.concat([ndf_a, ndf_b, ndf_c], ignore_index=True)\n",
    "print(ndf)\n",
    "\n",
    "sns.lineplot(data=ndf,x='Sample_number', y='Euler_val',hue='Euler_angle',lw=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## QUATERNIONS\n",
    "nqdf_q0=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q0.insert(1, 'Quaternion', str('q0'), True)\n",
    "nqdf_q0.insert(2, 'Q_val', df['q0'], True)\n",
    "\n",
    "nqdf_q1=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q1.insert(1, 'Quaternion', str('q1'), True)\n",
    "nqdf_q1.insert(2, 'Q_val', df['q1'], True)\n",
    "\n",
    "nqdf_q2=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q2.insert(1, 'Quaternion', str('q2'), True)\n",
    "nqdf_q2.insert(2, 'Q_val', df['q2'], True)\n",
    "\n",
    "nqdf_q3=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q3.insert(1, 'Quaternion', str('q3'), True)\n",
    "nqdf_q3.insert(2, 'Q_val', df['q3'], True)\n",
    "\n",
    "nqdf = pd.concat([nqdf_q0, nqdf_q1, nqdf_q2, nqdf_q3], ignore_index=True)\n",
    "print(nqdf)\n",
    "\n",
    "sns.lineplot(data=nqdf,x='Sample_number', y='Q_val',hue='Quaternion',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f28ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:44:12.264545Z",
     "start_time": "2023-06-24T22:44:11.535541Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(FULL_PATH_AND_CSV_FILE_02)\n",
    "# print(df)\n",
    "\n",
    "# # df = df.rename(columns={'Euler_computed [Roll, Pitch, Yaw]': 'Euler_computed'})\n",
    "df = df.rename(columns={'Sample number': 'Sample_number'})\n",
    "df = df.rename(columns={'Euler [Roll, Pitch, Yaw] LPMSB2': 'Euler_LPMSB2'})\n",
    "df = df.rename(columns={'Quaternions [q0, q1, q2, q3] LPMS-B2': 'Quaternions_LPMSB2'})\n",
    "\n",
    "df[['A','B','C']]=df.Euler_LPMSB2.str.split(',',expand=True)\n",
    "df['A']=df['A'].apply(   lambda x: x.replace('[','')   )\n",
    "df['C']=df['C'].apply(   lambda x:  x.replace(']','')   )\n",
    "df['A'] = pd.to_numeric(df['A'], errors='coerce')\n",
    "df['B'] = pd.to_numeric(df['B'], errors='coerce')\n",
    "df['C'] = pd.to_numeric(df['C'], errors='coerce')\n",
    "\n",
    "df[['q0','q1','q2', 'q3']]=df.Quaternions_LPMSB2.str.split(',',expand=True)\n",
    "df['q0']=df['q0'].apply(   lambda x: x.replace('[','')   )\n",
    "df['q3']=df['q3'].apply(   lambda x:  x.replace(']','')   )\n",
    "df['q0'] = pd.to_numeric(df['q0'], errors='coerce')\n",
    "df['q1'] = pd.to_numeric(df['q1'], errors='coerce')\n",
    "df['q2'] = pd.to_numeric(df['q2'], errors='coerce')\n",
    "df['q3'] = pd.to_numeric(df['q3'], errors='coerce')\n",
    "\n",
    "print(df.head())# #Print head of csv\n",
    "\n",
    "\n",
    "## EULER ANGLES\n",
    "ndf_a=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_a.insert(1, 'Euler_angle', str('alpha'), True)\n",
    "ndf_a.insert(2, 'Euler_val', df['A'], True)\n",
    "\n",
    "ndf_b=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_b.insert(1, 'Euler_angle', str('beta'), True)\n",
    "ndf_b.insert(2, 'Euler_val', df['B'], True)\n",
    "\n",
    "ndf_c=pd.DataFrame(data=df['Sample_number'])\n",
    "ndf_c.insert(1, 'Euler_angle', str('gamma'), True)\n",
    "ndf_c.insert(2, 'Euler_val', df['C'], True)\n",
    "\n",
    "ndf = pd.concat([ndf_a, ndf_b, ndf_c], ignore_index=True)\n",
    "print(ndf)\n",
    "\n",
    "sns.lineplot(data=ndf,x='Sample_number', y='Euler_val',hue='Euler_angle',lw=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## QUATERNIONS\n",
    "nqdf_q0=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q0.insert(1, 'Quaternion', str('q0'), True)\n",
    "nqdf_q0.insert(2, 'Q_val', df['q0'], True)\n",
    "\n",
    "nqdf_q1=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q1.insert(1, 'Quaternion', str('q1'), True)\n",
    "nqdf_q1.insert(2, 'Q_val', df['q1'], True)\n",
    "\n",
    "nqdf_q2=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q2.insert(1, 'Quaternion', str('q2'), True)\n",
    "nqdf_q2.insert(2, 'Q_val', df['q2'], True)\n",
    "\n",
    "nqdf_q3=pd.DataFrame(data=df['Sample_number'])\n",
    "nqdf_q3.insert(1, 'Quaternion', str('q3'), True)\n",
    "nqdf_q3.insert(2, 'Q_val', df['q3'], True)\n",
    "\n",
    "nqdf = pd.concat([nqdf_q0, nqdf_q1, nqdf_q2, nqdf_q3], ignore_index=True)\n",
    "print(nqdf)\n",
    "\n",
    "sns.lineplot(data=nqdf,x='Sample_number', y='Q_val',hue='Quaternion',lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c831cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658435d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
