{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ac01bc",
   "metadata": {},
   "source": [
    "# Analysis of Video and Image Data for cropping and texture features\n",
    "Author(s): Miguel Xochicale @mxochicale    \n",
    "Contributor(s): \n",
    "\n",
    "## History\n",
    "* 17th May 2022: Add prototype\n",
    "\n",
    "## Summary\n",
    "\n",
    "\n",
    "### How to run the notebook\n",
    "1. Go to repository path: `$HOME/repositories/`\n",
    "Open repo in pycharm and in the terminal type:\n",
    "```\n",
    "git checkout main # or the branch\n",
    "git pull # to bring a local branch up-to-date with its remote version\n",
    "```\n",
    "\n",
    "2. Launch Notebook server. Go to you repository path: cd $HOME/repositories/ and type in the pycharm terminal:\n",
    "```\n",
    "conda activate *VE \n",
    "jupyter notebook --browser=firefox\n",
    "```\n",
    "which will open your web-browser.\n",
    "\n",
    "## References \n",
    "1. https://stackoverflow.com/questions/45704999/how-to-convert-vector-wrapped-as-string-to-numpy-array-in-pandas-dataframe\n",
    "2. https://github.com/YuxinZhaozyx/pytorch-VideoDataset/blob/master/datasets.py (Future work)\n",
    "3. https://stackoverflow.com/questions/65446464/how-to-convert-a-video-in-numpy-array\n",
    "4. https://matplotlib.org/stable/gallery/specialty_plots/mri_with_eeg.html#sphx-glr-gallery-specialty-plots-mri-with-eeg-py \n",
    "5. https://www.researchgate.net/publication/326881329_Medical_image_security_enhancement_using_two_dimensional_chaotic_mapping_optimized_by_self-adaptive_grey_wolf_algorithm \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf80206",
   "metadata": {},
   "source": [
    "## Setting imports and datasets paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190058c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:41:47.145415Z",
     "start_time": "2023-06-24T22:41:47.136830Z"
    }
   },
   "outputs": [],
   "source": [
    "from rtt4ssa.utils.utils import video_to_tensor, compute_texture_array_and_plot\n",
    "from rtt4ssa.utils.utils import get_and_plot_data_frame_of_texture_analysis\n",
    "from rtt4ssa.utils.utils import get_and_plot_imu_data_analysis\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from typing import Tuple, List\n",
    "\n",
    "HOME_PATH = os.path.expanduser(f'~')\n",
    "USERNAME = os.path.split(HOME_PATH)[1]\n",
    "REPOSITORY_PATH='repositories/rtt4ssa'\n",
    "\n",
    "\n",
    "###########################\n",
    "###SET DATA_PATH \n",
    "DATA_PATH='rtt4ssa/sensor_fusion'\n",
    "FULL_REPO_DATA_PATH = HOME_PATH +'/' + REPOSITORY_PATH +'/' + DATA_PATH\n",
    "\n",
    "\n",
    "###########################\n",
    "### experiments_23-aug-2022\n",
    "AVI_FILE = 'testNN.avi'\n",
    "CSV_FILE = 'testNN.avi.csv'\n",
    "\n",
    "FULL_PATH_AND_AVI_FILE = os.path.join(FULL_REPO_DATA_PATH , AVI_FILE)\n",
    "FULL_PATH_AND_CSV_FILE = os.path.join(FULL_REPO_DATA_PATH , CSV_FILE)\n",
    "\n",
    "\n",
    "## Printing Versions and paths\n",
    "print(f'PyTorch Version: {torch.__version__}')\n",
    "print(f'pandas Version: {pd.__version__}')\n",
    "print(f'seaborn Version: {sns.__version__}')\n",
    "print(f'numpy Version: {np.__version__}')\n",
    "print(f'cv2 Version: {cv2.__version__}')\n",
    "print(f'skimage Version: {skimage.__version__}')\n",
    "\n",
    "print(f'FULL_REPO_DATA_PATH: {FULL_REPO_DATA_PATH}')\n",
    "print(f'FULL_PATH_AND_CSV_FILE: {FULL_PATH_AND_CSV_FILE}')\n",
    "print(f'FULL_PATH_AND_AVI_FILE: {FULL_PATH_AND_AVI_FILE}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc94bcd",
   "metadata": {},
   "source": [
    "# Reading video and plotting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491eb8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:26.918418Z",
     "start_time": "2023-06-24T22:43:26.912257Z"
    }
   },
   "outputs": [],
   "source": [
    "start_frame_number = 000\n",
    "end_frame_number = 50\n",
    "\n",
    "total_number_of_frames = end_frame_number - start_frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f4372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:30.904233Z",
     "start_time": "2023-06-24T22:43:27.564573Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "video, frames_timestamp = video_to_tensor(FULL_PATH_AND_AVI_FILE, start_frame_number, end_frame_number)\n",
    "\n",
    "# print(type(video))#<class 'numpy.ndarray'>\n",
    "num_frames, height, width = video.shape\n",
    "print(f'num_frames: {num_frames}')\n",
    "print(f'height: {height}')\n",
    "print(f'width: {width}')\n",
    "#num_frames, height, width, channels = video.shape\n",
    "# print(f'channels: {channels}')\n",
    "# print(video[0].shape)#(480, 640, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aca3e3",
   "metadata": {},
   "source": [
    "# Plotting texture analysis of all frames in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed983d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:46.518000Z",
     "start_time": "2023-06-24T22:43:40.615453Z"
    }
   },
   "outputs": [],
   "source": [
    "display_factor = 400    \n",
    "texture_analysis_array = compute_texture_array_and_plot(video, frames_timestamp, display_factor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56537774",
   "metadata": {},
   "source": [
    "# Plotting texture analysis of all frames in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d2e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:43:59.892073Z",
     "start_time": "2023-06-24T22:43:58.621981Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_texture_analysis = get_and_plot_data_frame_of_texture_analysis(texture_analysis_array, total_number_of_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_texture_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e37dd6",
   "metadata": {},
   "source": [
    "## Reading and ploting csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06effe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T22:44:12.264545Z",
     "start_time": "2023-06-24T22:44:11.535541Z"
    }
   },
   "outputs": [],
   "source": [
    "    df, ndf, nqdf = get_and_plot_imu_data_analysis(FULL_PATH_AND_CSV_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nqdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c831cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658435d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
